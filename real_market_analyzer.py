"""
ì‹¤ì‹œê°„ ì‹œì¥ ë¶„ì„ ëª¨ë“ˆ
- ì›¹ ìŠ¤í¬ë˜í•‘ìœ¼ë¡œ ì‹¤ì œ ì‹œì¥ ë°ì´í„° ìˆ˜ì§‘
- ë‹¤ì¤‘ í”Œë«í¼ ì‹œì¥ ë¶„ì„
- ê²½ìŸì‚¬ ë° ìˆ˜ìš” ìë™ íŒŒì•…
"""

import requests
from bs4 import BeautifulSoup
import json
from datetime import datetime
import time
from urllib.parse import quote

class RealMarketAnalyzer:
    def __init__(self):
        self.headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
        }

    def analyze_kmong_market(self, keyword):
        """í¬ëª½ì—ì„œ ì‹¤ì œ ì‹œì¥ ë°ì´í„° ìˆ˜ì§‘"""
        try:
            url = f"https://kmong.com/search?keyword={quote(keyword)}"
            response = requests.get(url, headers=self.headers, timeout=10)
            soup = BeautifulSoup(response.content, 'html.parser')

            # ì„œë¹„ìŠ¤ ê°œìˆ˜ íŒŒì•…
            services = soup.find_all('div', class_='service-card')

            prices = []
            reviews = []
            for service in services[:20]:  # ìƒìœ„ 20ê°œë§Œ
                try:
                    price_elem = service.find('span', class_='price')
                    if price_elem:
                        price_text = price_elem.text.replace(',', '').replace('ì›', '')
                        prices.append(int(price_text))

                    review_elem = service.find('span', class_='review-count')
                    if review_elem:
                        review_count = int(review_elem.text.replace('(', '').replace(')', ''))
                        reviews.append(review_count)
                except:
                    continue

            return {
                'platform': 'í¬ëª½',
                'service_count': len(services),
                'avg_price': sum(prices) // len(prices) if prices else 0,
                'min_price': min(prices) if prices else 0,
                'max_price': max(prices) if prices else 0,
                'avg_reviews': sum(reviews) // len(reviews) if reviews else 0,
                'competition_level': self._calculate_competition(len(services)),
                'market_saturation': self._calculate_saturation(len(services), sum(reviews))
            }
        except Exception as e:
            print(f"í¬ëª½ ë¶„ì„ ì‹¤íŒ¨: {e}")
            return {'platform': 'í¬ëª½', 'error': str(e)}

    def analyze_naver_search_volume(self, keyword):
        """ë„¤ì´ë²„ ê²€ìƒ‰ëŸ‰ ì¶”ì •"""
        try:
            url = f"https://search.naver.com/search.naver?query={quote(keyword)}"
            response = requests.get(url, headers=self.headers, timeout=10)

            # ìë™ì™„ì„± ê²€ìƒ‰ì–´ë¡œ ì¸ê¸°ë„ ì¶”ì •
            autocomplete_url = f"https://ac.search.naver.com/nx/ac?q={quote(keyword)}&con=0&frm=nv&ans=2&r_format=json&r_enc=UTF-8&r_unicode=0&t_koreng=1&run=2&rev=4&q_enc=UTF-8&st=100&r_lt=10000"
            ac_response = requests.get(autocomplete_url, timeout=10)

            if ac_response.status_code == 200:
                data = ac_response.json()
                suggestions = data.get('items', [[]])[0]

                return {
                    'keyword': keyword,
                    'related_searches': len(suggestions),
                    'popularity_score': min(len(suggestions) * 10, 100),
                    'suggestions': suggestions[:5]
                }
        except Exception as e:
            print(f"ë„¤ì´ë²„ ê²€ìƒ‰ëŸ‰ ë¶„ì„ ì‹¤íŒ¨: {e}")
            return {'keyword': keyword, 'error': str(e)}

    def analyze_competitors_google(self, keyword):
        """êµ¬ê¸€ ê²€ìƒ‰ìœ¼ë¡œ ê²½ìŸì‚¬ íŒŒì•…"""
        try:
            url = f"https://www.google.com/search?q={quote(keyword + ' ì„œë¹„ìŠ¤')}"
            response = requests.get(url, headers=self.headers, timeout=10)
            soup = BeautifulSoup(response.content, 'html.parser')

            # ê²€ìƒ‰ ê²°ê³¼ ê°œìˆ˜ íŒŒì•…
            results = soup.find_all('div', class_='g')

            # ê´‘ê³  ì—¬ë¶€ í™•ì¸
            ads = soup.find_all('div', {'data-text-ad': True})

            return {
                'organic_results': len(results),
                'paid_ads': len(ads),
                'has_competition': len(results) > 0,
                'ad_competition': 'high' if len(ads) > 5 else 'medium' if len(ads) > 0 else 'low',
                'entry_difficulty': 'hard' if len(ads) > 5 and len(results) > 50 else 'medium' if len(results) > 20 else 'easy'
            }
        except Exception as e:
            print(f"êµ¬ê¸€ ê²½ìŸì‚¬ ë¶„ì„ ì‹¤íŒ¨: {e}")
            return {'error': str(e)}

    def analyze_youtube_interest(self, keyword):
        """ìœ íŠœë¸Œ ê´€ì‹¬ë„ ë¶„ì„"""
        try:
            url = f"https://www.youtube.com/results?search_query={quote(keyword)}"
            response = requests.get(url, headers=self.headers, timeout=10)

            # ê°„ë‹¨í•œ ê´€ì‹¬ë„ ì¶”ì • (ì‘ë‹µ í¬ê¸° ê¸°ë°˜)
            content_length = len(response.content)

            return {
                'interest_indicator': 'high' if content_length > 500000 else 'medium' if content_length > 300000 else 'low',
                'estimated_videos': content_length // 10000  # ëŒ€ëµì  ì¶”ì •
            }
        except Exception as e:
            print(f"ìœ íŠœë¸Œ ê´€ì‹¬ë„ ë¶„ì„ ì‹¤íŒ¨: {e}")
            return {'error': str(e)}

    def analyze_wishket_market(self, keyword):
        """ìœ„ì‹œì¼“ í”„ë¦¬ëœì„œ ì‹œì¥ ë¶„ì„"""
        try:
            url = f"https://www.wishket.com/project/?q={quote(keyword)}"
            response = requests.get(url, headers=self.headers, timeout=10)
            soup = BeautifulSoup(response.content, 'html.parser')

            # í”„ë¡œì íŠ¸ ê°œìˆ˜ íŒŒì•…
            projects = soup.find_all('div', class_='project-card') or soup.find_all('div', class_='item')

            # í‰ê·  ì˜ˆì‚° ì¶”ì •
            budgets = []
            for project in projects[:10]:
                try:
                    budget_elem = project.find('span', class_='budget') or project.find('div', class_='price')
                    if budget_elem:
                        budget_text = budget_elem.text.replace(',', '').replace('ë§Œì›', '0000').replace('ì›', '')
                        budgets.append(int(budget_text))
                except:
                    continue

            return {
                'platform': 'ìœ„ì‹œì¼“',
                'project_count': len(projects),
                'avg_budget': sum(budgets) // len(budgets) if budgets else 0,
                'demand_level': 'high' if len(projects) > 20 else 'medium' if len(projects) > 5 else 'low',
                'market_active': len(projects) > 0
            }
        except Exception as e:
            print(f"ìœ„ì‹œì¼“ ë¶„ì„ ì‹¤íŒ¨: {e}")
            return {'platform': 'ìœ„ì‹œì¼“', 'error': str(e)}

    def analyze_soomgo_market(self, keyword):
        """ìˆ¨ê³  ì„œë¹„ìŠ¤ ì‹œì¥ ë¶„ì„"""
        try:
            url = f"https://soomgo.com/search/pro?keyword={quote(keyword)}"
            response = requests.get(url, headers=self.headers, timeout=10)
            soup = BeautifulSoup(response.content, 'html.parser')

            # ì „ë¬¸ê°€ ê°œìˆ˜
            pros = soup.find_all('div', class_='pro-card') or soup.find_all('a', class_='pro-item')

            # ë¦¬ë·° ìˆ˜ íŒŒì•…
            reviews = []
            for pro in pros[:20]:
                try:
                    review_elem = pro.find('span', class_='review-count')
                    if review_elem:
                        review_count = int(review_elem.text.replace('ë¦¬ë·°', '').replace(',', '').strip())
                        reviews.append(review_count)
                except:
                    continue

            return {
                'platform': 'ìˆ¨ê³ ',
                'expert_count': len(pros),
                'avg_reviews': sum(reviews) // len(reviews) if reviews else 0,
                'competition': 'high' if len(pros) > 50 else 'medium' if len(pros) > 10 else 'low',
                'market_maturity': 'mature' if sum(reviews) > 500 else 'growing'
            }
        except Exception as e:
            print(f"ìˆ¨ê³  ë¶„ì„ ì‹¤íŒ¨: {e}")
            return {'platform': 'ìˆ¨ê³ ', 'error': str(e)}

    def analyze_brokerage_platforms(self, keyword):
        """ì¤‘ê°œ í”Œë«í¼ ì¢…í•© ë¶„ì„ (íƒˆì‰, í”„ë¦½ ë“±)"""
        try:
            # íƒˆì‰ (ì¬ëŠ¥ ë§ˆì¼“)
            taling_url = f"https://taling.me/search?keyword={quote(keyword)}"
            response = requests.get(taling_url, headers=self.headers, timeout=10)
            soup = BeautifulSoup(response.content, 'html.parser')

            classes = soup.find_all('div', class_='class-card') or soup.find_all('a', class_='talent-item')

            return {
                'platform': 'íƒˆì‰',
                'class_count': len(classes),
                'market_presence': len(classes) > 0,
                'category': 'êµìœ¡/ì¬ëŠ¥ê³µìœ '
            }
        except Exception as e:
            print(f"ì¤‘ê°œ í”Œë«í¼ ë¶„ì„ ì‹¤íŒ¨: {e}")
            return {'platform': 'ì¤‘ê°œí”Œë«í¼', 'error': str(e)}

    def analyze_coupang_marketplace(self, keyword):
        """ì¿ íŒ¡ ë§ˆì¼“í”Œë ˆì´ìŠ¤ ë¶„ì„"""
        try:
            url = f"https://www.coupang.com/np/search?q={quote(keyword)}"
            response = requests.get(url, headers=self.headers, timeout=10)
            soup = BeautifulSoup(response.content, 'html.parser')

            # ìƒí’ˆ ê°œìˆ˜
            products = soup.find_all('li', class_='search-product') or soup.find_all('a', class_='search-product-link')

            # ê°€ê²© ì •ë³´
            prices = []
            for product in products[:20]:
                try:
                    price_elem = product.find('strong', class_='price-value')
                    if price_elem:
                        price = int(price_elem.text.replace(',', ''))
                        prices.append(price)
                except:
                    continue

            return {
                'platform': 'ì¿ íŒ¡',
                'product_count': len(products),
                'avg_price': sum(prices) // len(prices) if prices else 0,
                'e_commerce_potential': 'high' if len(products) > 100 else 'medium' if len(products) > 20 else 'low'
            }
        except Exception as e:
            print(f"ì¿ íŒ¡ ë¶„ì„ ì‹¤íŒ¨: {e}")
            return {'platform': 'ì¿ íŒ¡', 'error': str(e)}

    def analyze_blog_trend(self, keyword):
        """ë„¤ì´ë²„ ë¸”ë¡œê·¸ íŠ¸ë Œë“œ ë¶„ì„"""
        try:
            url = f"https://section.blog.naver.com/Search/Post.naver?keyword={quote(keyword)}"
            response = requests.get(url, headers=self.headers, timeout=10)
            soup = BeautifulSoup(response.content, 'html.parser')

            # ë¸”ë¡œê·¸ í¬ìŠ¤íŠ¸ ê°œìˆ˜
            posts = soup.find_all('div', class_='desc_inner') or soup.find_all('a', class_='post_link')

            return {
                'platform': 'ë„¤ì´ë²„ ë¸”ë¡œê·¸',
                'post_count': len(posts),
                'content_volume': 'high' if len(posts) > 30 else 'medium' if len(posts) > 10 else 'low',
                'trend_indicator': 'ìƒìŠ¹ì¤‘' if len(posts) > 20 else 'ë³´í†µ'
            }
        except Exception as e:
            print(f"ë¸”ë¡œê·¸ íŠ¸ë Œë“œ ë¶„ì„ ì‹¤íŒ¨: {e}")
            return {'platform': 'ë„¤ì´ë²„ ë¸”ë¡œê·¸', 'error': str(e)}

    def analyze_instagram_business(self, keyword):
        """ì¸ìŠ¤íƒ€ê·¸ë¨ ë¹„ì¦ˆë‹ˆìŠ¤ í™œì„±ë„ ë¶„ì„"""
        try:
            # ì¸ìŠ¤íƒ€ê·¸ë¨ì€ ë¡œê·¸ì¸ í•„ìš”í•˜ë¯€ë¡œ ê°„ì ‘ ì§€í‘œ ì‚¬ìš©
            # ë„¤ì´ë²„ì—ì„œ "keyword ì¸ìŠ¤íƒ€ê·¸ë¨" ê²€ìƒ‰
            url = f"https://search.naver.com/search.naver?query={quote(keyword + ' ì¸ìŠ¤íƒ€ê·¸ë¨')}"
            response = requests.get(url, headers=self.headers, timeout=10)

            content_length = len(response.content)

            return {
                'platform': 'ì¸ìŠ¤íƒ€ê·¸ë¨',
                'social_presence': 'high' if content_length > 300000 else 'medium' if content_length > 150000 else 'low',
                'marketing_potential': 'SNS ë§ˆì¼€íŒ… ê°€ëŠ¥' if content_length > 200000 else 'ì œí•œì '
            }
        except Exception as e:
            print(f"ì¸ìŠ¤íƒ€ê·¸ë¨ ë¶„ì„ ì‹¤íŒ¨: {e}")
            return {'platform': 'ì¸ìŠ¤íƒ€ê·¸ë¨', 'error': str(e)}

    def _calculate_competition(self, service_count):
        """ê²½ìŸ ê°•ë„ ê³„ì‚°"""
        if service_count > 100:
            return 'very_high'
        elif service_count > 50:
            return 'high'
        elif service_count > 20:
            return 'medium'
        elif service_count > 5:
            return 'low'
        else:
            return 'very_low'

    def _calculate_saturation(self, service_count, total_reviews):
        """ì‹œì¥ í¬í™”ë„ ê³„ì‚°"""
        if service_count == 0:
            return 'unexplored'

        avg_reviews_per_service = total_reviews / service_count if service_count > 0 else 0

        if avg_reviews_per_service > 100:
            return 'saturated'
        elif avg_reviews_per_service > 50:
            return 'competitive'
        elif avg_reviews_per_service > 10:
            return 'growing'
        else:
            return 'emerging'

    def comprehensive_analysis(self, business_idea, keyword):
        """ì¢…í•© ì‹œì¥ ë¶„ì„"""
        print(f"\n{'='*60}")
        print(f"ì‹œì¥ ë¶„ì„ ì‹œì‘: {business_idea}")
        print(f"í‚¤ì›Œë“œ: {keyword}")
        print(f"{'='*60}\n")

        results = {
            'business_idea': business_idea,
            'keyword': keyword,
            'analysis_date': datetime.now().isoformat(),
            'data_sources': {}
        }

        # í¬ëª½ ë¶„ì„
        print("1. í¬ëª½ ì‹œì¥ ë¶„ì„ ì¤‘...")
        kmong_data = self.analyze_kmong_market(keyword)
        results['data_sources']['kmong'] = kmong_data
        time.sleep(2)  # API í˜¸ì¶œ ê°„ê²©

        # ë„¤ì´ë²„ ê²€ìƒ‰ëŸ‰
        print("2. ë„¤ì´ë²„ ê²€ìƒ‰ëŸ‰ ë¶„ì„ ì¤‘...")
        naver_data = self.analyze_naver_search_volume(keyword)
        results['data_sources']['naver'] = naver_data
        time.sleep(2)

        # êµ¬ê¸€ ê²½ìŸì‚¬
        print("3. êµ¬ê¸€ ê²½ìŸì‚¬ ë¶„ì„ ì¤‘...")
        google_data = self.analyze_competitors_google(keyword)
        results['data_sources']['google'] = google_data
        time.sleep(2)

        # ìœ íŠœë¸Œ ê´€ì‹¬ë„
        print("4. ìœ íŠœë¸Œ ê´€ì‹¬ë„ ë¶„ì„ ì¤‘...")
        youtube_data = self.analyze_youtube_interest(keyword)
        results['data_sources']['youtube'] = youtube_data
        time.sleep(2)

        # ìœ„ì‹œì¼“ í”„ë¦¬ëœì„œ ì‹œì¥
        print("5. ìœ„ì‹œì¼“ í”„ë¦¬ëœì„œ ì‹œì¥ ë¶„ì„ ì¤‘...")
        wishket_data = self.analyze_wishket_market(keyword)
        results['data_sources']['wishket'] = wishket_data
        time.sleep(2)

        # ìˆ¨ê³  ì„œë¹„ìŠ¤ ì‹œì¥
        print("6. ìˆ¨ê³  ì„œë¹„ìŠ¤ ì‹œì¥ ë¶„ì„ ì¤‘...")
        soomgo_data = self.analyze_soomgo_market(keyword)
        results['data_sources']['soomgo'] = soomgo_data
        time.sleep(2)

        # íƒˆì‰ êµìœ¡/ì¬ëŠ¥ í”Œë«í¼
        print("7. íƒˆì‰ í”Œë«í¼ ë¶„ì„ ì¤‘...")
        brokerage_data = self.analyze_brokerage_platforms(keyword)
        results['data_sources']['brokerage'] = brokerage_data
        time.sleep(2)

        # ì¿ íŒ¡ ë§ˆì¼“í”Œë ˆì´ìŠ¤
        print("8. ì¿ íŒ¡ ë§ˆì¼“í”Œë ˆì´ìŠ¤ ë¶„ì„ ì¤‘...")
        coupang_data = self.analyze_coupang_marketplace(keyword)
        results['data_sources']['coupang'] = coupang_data
        time.sleep(2)

        # ë„¤ì´ë²„ ë¸”ë¡œê·¸ íŠ¸ë Œë“œ
        print("9. ë„¤ì´ë²„ ë¸”ë¡œê·¸ íŠ¸ë Œë“œ ë¶„ì„ ì¤‘...")
        blog_data = self.analyze_blog_trend(keyword)
        results['data_sources']['blog'] = blog_data
        time.sleep(2)

        # ì¸ìŠ¤íƒ€ê·¸ë¨ ë¹„ì¦ˆë‹ˆìŠ¤
        print("10. ì¸ìŠ¤íƒ€ê·¸ë¨ ë¹„ì¦ˆë‹ˆìŠ¤ í™œì„±ë„ ë¶„ì„ ì¤‘...")
        instagram_data = self.analyze_instagram_business(keyword)
        results['data_sources']['instagram'] = instagram_data

        # ì¢…í•© ì ìˆ˜ ê³„ì‚°
        results['market_score'] = self._calculate_market_score(results['data_sources'])
        results['recommendation'] = self._generate_recommendation(results['market_score'])

        print(f"\n{'='*60}")
        print(f"ë¶„ì„ ì™„ë£Œ!")
        print(f"ì‹œì¥ ì ìˆ˜: {results['market_score']}/100")
        print(f"ì¶”ì²œ ì—¬ë¶€: {results['recommendation']['verdict']}")
        print(f"{'='*60}\n")

        return results

    def _calculate_market_score(self, data_sources):
        """ì¢…í•© ì‹œì¥ ì ìˆ˜ ê³„ì‚° (0-100) - 10ê°œ í”Œë«í¼ í†µí•©"""
        score = 0

        # í¬ëª½ ë°ì´í„° í‰ê°€ (20ì )
        kmong = data_sources.get('kmong', {})
        if not kmong.get('error'):
            competition = kmong.get('competition_level', 'high')
            if competition == 'very_low':
                score += 15
            elif competition == 'low':
                score += 12
            elif competition == 'medium':
                score += 10
            elif competition == 'high':
                score += 5

            avg_price = kmong.get('avg_price', 0)
            if avg_price > 100000:
                score += 5
            elif avg_price > 50000:
                score += 3
            elif avg_price > 20000:
                score += 2

        # ë„¤ì´ë²„ ì¸ê¸°ë„ (15ì )
        naver = data_sources.get('naver', {})
        if not naver.get('error'):
            popularity = naver.get('popularity_score', 0)
            score += min(popularity * 0.15, 15)

        # êµ¬ê¸€ ê²½ìŸ ê°•ë„ (10ì )
        google = data_sources.get('google', {})
        if not google.get('error'):
            difficulty = google.get('entry_difficulty', 'hard')
            if difficulty == 'easy':
                score += 10
            elif difficulty == 'medium':
                score += 7
            elif difficulty == 'hard':
                score += 3

        # ìœ íŠœë¸Œ ê´€ì‹¬ë„ (5ì )
        youtube = data_sources.get('youtube', {})
        if not youtube.get('error'):
            interest = youtube.get('interest_indicator', 'low')
            if interest == 'high':
                score += 5
            elif interest == 'medium':
                score += 3
            elif interest == 'low':
                score += 1

        # ìœ„ì‹œì¼“ í”„ë¦¬ëœì„œ ì‹œì¥ (15ì )
        wishket = data_sources.get('wishket', {})
        if not wishket.get('error'):
            demand = wishket.get('demand_level', 'low')
            if demand == 'high':
                score += 10
            elif demand == 'medium':
                score += 6
            elif demand == 'low':
                score += 2

            avg_budget = wishket.get('avg_budget', 0)
            if avg_budget > 2000000:
                score += 5
            elif avg_budget > 1000000:
                score += 3
            elif avg_budget > 500000:
                score += 2

        # ìˆ¨ê³  ì„œë¹„ìŠ¤ ì‹œì¥ (10ì )
        soomgo = data_sources.get('soomgo', {})
        if not soomgo.get('error'):
            competition = soomgo.get('competition', 'high')
            if competition == 'low':
                score += 7
            elif competition == 'medium':
                score += 5
            elif competition == 'high':
                score += 2

            expert_count = soomgo.get('expert_count', 0)
            if expert_count > 0:
                score += 3

        # íƒˆì‰ êµìœ¡/ì¬ëŠ¥ í”Œë«í¼ (5ì )
        brokerage = data_sources.get('brokerage', {})
        if not brokerage.get('error'):
            if brokerage.get('market_presence'):
                score += 3
            class_count = brokerage.get('class_count', 0)
            if class_count > 10:
                score += 2
            elif class_count > 0:
                score += 1

        # ì¿ íŒ¡ ë§ˆì¼“í”Œë ˆì´ìŠ¤ (10ì )
        coupang = data_sources.get('coupang', {})
        if not coupang.get('error'):
            potential = coupang.get('e_commerce_potential', 'low')
            if potential == 'high':
                score += 7
            elif potential == 'medium':
                score += 4

            product_count = coupang.get('product_count', 0)
            if product_count > 50:
                score += 3
            elif product_count > 10:
                score += 2

        # ë„¤ì´ë²„ ë¸”ë¡œê·¸ íŠ¸ë Œë“œ (5ì )
        blog = data_sources.get('blog', {})
        if not blog.get('error'):
            trend = blog.get('trend_indicator', 'ë³´í†µ')
            if trend == 'ìƒìŠ¹ì¤‘':
                score += 5
            elif trend == 'ë³´í†µ':
                score += 3

        # ì¸ìŠ¤íƒ€ê·¸ë¨ ë¹„ì¦ˆë‹ˆìŠ¤ (5ì )
        instagram = data_sources.get('instagram', {})
        if not instagram.get('error'):
            presence = instagram.get('social_presence', 'low')
            if presence == 'high':
                score += 5
            elif presence == 'medium':
                score += 3

        return min(int(score), 100)

    def _generate_recommendation(self, score):
        """ì ìˆ˜ ê¸°ë°˜ ì¶”ì²œ ìƒì„±"""
        if score >= 80:
            return {
                'verdict': 'ë§¤ìš° ìœ ë§',
                'action': 'ì¦‰ì‹œ ì‹¤í–‰ ê³„íš ìˆ˜ë¦½ ê¶Œì¥',
                'priority': 'high',
                'confidence': 'ë†’ìŒ'
            }
        elif score >= 60:
            return {
                'verdict': 'ìœ ë§',
                'action': 'ì¶”ê°€ ê²€ì¦ í›„ ì§„í–‰',
                'priority': 'medium',
                'confidence': 'ì¤‘ê°„'
            }
        elif score >= 40:
            return {
                'verdict': 'ë³´í†µ',
                'action': 'ì‹ ì¤‘í•œ ì ‘ê·¼ í•„ìš”',
                'priority': 'low',
                'confidence': 'ë‚®ìŒ'
            }
        else:
            return {
                'verdict': 'ë¹„ì¶”ì²œ',
                'action': 'ë‹¤ë¥¸ ì•„ì´ë””ì–´ íƒìƒ‰',
                'priority': 'none',
                'confidence': 'ë§¤ìš° ë‚®ìŒ'
            }

    def save_analysis(self, results, filename='market_analysis.json'):
        """ë¶„ì„ ê²°ê³¼ ì €ì¥"""
        with open(filename, 'w', encoding='utf-8') as f:
            json.dump(results, f, ensure_ascii=False, indent=2)
        print(f"ë¶„ì„ ê²°ê³¼ ì €ì¥ë¨: {filename}")


# ì‚¬ìš© ì˜ˆì‹œ
if __name__ == "__main__":
    analyzer = RealMarketAnalyzer()

    # IT ì‚¬ì—… ì•„ì´ë””ì–´ ë¶„ì„
    test_ideas = [
        ("ì›¹ì‚¬ì´íŠ¸ ì œì‘ ì„œë¹„ìŠ¤", "í™ˆí˜ì´ì§€ ì œì‘"),
        ("SEO ì»¨ì„¤íŒ…", "ê²€ìƒ‰ì—”ì§„ìµœì í™”"),
        ("ì±—ë´‡ ê°œë°œ", "ì±—ë´‡ ì œì‘"),
        ("ëª¨ë°”ì¼ ì•± ê°œë°œ", "ì•± ê°œë°œ"),
        ("ë§ˆì¼€íŒ… ìë™í™”", "ë§ˆì¼€íŒ… ìë™í™”")
    ]

    all_results = []

    for business_idea, keyword in test_ideas:
        result = analyzer.comprehensive_analysis(business_idea, keyword)
        all_results.append(result)

        # ê²°ê³¼ ì¶œë ¥
        print(f"\nğŸ“Š {business_idea}")
        print(f"   í‚¤ì›Œë“œ: {keyword}")
        print(f"   ì‹œì¥ ì ìˆ˜: {result['market_score']}/100")
        print(f"   ì¶”ì²œ: {result['recommendation']['verdict']}")
        print(f"   ìš°ì„ ìˆœìœ„: {result['recommendation']['priority']}")
        print("-" * 60)

        time.sleep(5)  # API í˜¸ì¶œ ê°„ê²©

    # ìƒìœ„ 3ê°œ ì¶”ì²œ
    all_results.sort(key=lambda x: x['market_score'], reverse=True)

    print("\n" + "="*60)
    print("ğŸ† TOP 3 ì¶”ì²œ ì‚¬ì—…")
    print("="*60)

    for i, result in enumerate(all_results[:3], 1):
        print(f"\n{i}. {result['business_idea']}")
        print(f"   ì ìˆ˜: {result['market_score']}/100")
        print(f"   ì¶”ì²œ: {result['recommendation']['action']}")

        kmong = result['data_sources'].get('kmong', {})
        if not kmong.get('error'):
            print(f"   í‰ê·  ê°€ê²©: {kmong.get('avg_price', 0):,}ì›")
            print(f"   ê²½ìŸ ê°•ë„: {kmong.get('competition_level', 'N/A')}")

    # ì „ì²´ ê²°ê³¼ ì €ì¥
    analyzer.save_analysis({
        'analysis_date': datetime.now().isoformat(),
        'total_analyzed': len(all_results),
        'results': all_results
    }, 'comprehensive_market_analysis.json')
